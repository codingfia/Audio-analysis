# Audio-analysis

This a project focused on Speech Emotion Recognition using LSTM and CNN. We aim to recognize human emotion and affective states from speech. 

Datasets used in this projectï¼š

Crowd-sourced Emotional Mutimodal Actors Dataset (Crema-D)
Ryerson Audio-Visual Database of Emotional Speech and Song (Ravdess)
Surrey Audio-Visual Expressed Emotion (Savee)
Toronto emotional speech set (Tess)
We recognize seven emotions (angry, fear, disgust, sad, happy, neutral, surprise) from 4 speech datasets, composed of 10239 speech samples, with 97% accuracy of the CNN model.
